{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from skimage.color import rgb2gray,rgba2rgb\n",
    "from skimage.measure import find_contours\n",
    "from skimage import transform, feature, color , morphology , measure, segmentation, filters, draw, io\n",
    "from commonfunctions import * \n",
    "from skimage.draw import rectangle\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Imag and handle its orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the imag\n",
    "\n",
    "def deskew_image(img):\n",
    "    # Read the image\n",
    "    image = np.copy(img)\n",
    "    gray = color.rgb2gray(image)\n",
    "\n",
    "    # Apply edge detection using Canny\n",
    "    edges = feature.canny(gray, sigma=1.0, low_threshold=0.1, high_threshold=0.9)\n",
    "\n",
    "    # Use probabilistic Hough Transform to detect lines\n",
    "    lines = transform.probabilistic_hough_line(edges, threshold=10, line_length=5, line_gap=3)\n",
    "    \n",
    "    # Determine the dominant angle of the lines\n",
    "    angles = [np.arctan2((y2 - y1), (x2 - x1)) for (x1, y1), (x2, y2) in lines]\n",
    "    dominant_angle = np.median(angles) * 180 / np.pi\n",
    "\n",
    "    # Rotate the image to correct skewing and orientation\n",
    "    rotated_image = transform.rotate(image, dominant_angle, resize=True)\n",
    "\n",
    "    return rotated_image\n",
    "# image 4,15 is the only one that is rotated wrong \n",
    "\n",
    "deskewed_images = list()\n",
    "\n",
    "# for i in range(10,15):\n",
    "#     image = io.imread('grade_sheet/{}.jpg'.format(i))\n",
    "#     deskewed_image = deskew_image(image)\n",
    "#     show_images([image,deskewed_image], ['image', 'deskewed_image'])\n",
    "#     deskewed_images.append(deskewed_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(img):\n",
    "    # Apply Gaussian blur\n",
    "    image = np.copy(img)\n",
    "    \n",
    "    blurred = color.rgb2gray(image)\n",
    "    blurred = blurred > .5\n",
    "\n",
    "    # Perform morphological operations to close gaps in edges\n",
    "    blurred = morphology.closing(blurred, morphology.square(6))\n",
    "\n",
    "    # Label connected components (no effect)\n",
    "    label_image = measure.label(blurred)\n",
    "\n",
    "    # Find contours using scikit-image\n",
    "    cnts = measure.find_contours(label_image, .5)\n",
    "\n",
    "    max_area = 0\n",
    "    max_box = None\n",
    "    for cnt in cnts:\n",
    "        Xmin = int(round(min(cnt[:,1])))\n",
    "        Xmax = int(round(max(cnt[:,1])))\n",
    "        Ymin = int(round(min(cnt[:,0])))\n",
    "        Ymax = int(round(max(cnt[:,0])))\n",
    "\n",
    "        width = abs( Xmax - Xmin) \n",
    "        height = abs(Ymax - Ymin)\n",
    "        area = width * height \n",
    "        \n",
    "        if area > max_area:\n",
    "            max_area = area \n",
    "            max_box = [Xmin, Xmax, Ymin, Ymax]\n",
    "\n",
    "    [Xmin, Xmax, Ymin, Ymax] = max_box\n",
    "    print(max_box)\n",
    "    rr, cc = rectangle(start = (Ymin,Xmin), end = (Ymax,Xmax), shape=image.shape)\n",
    "    image[rr, cc] = [255,255,255] #set color white\n",
    "    return max_box, image\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(1,10):\n",
    "#     image = io.imread('grade_sheet/{}.jpg'.format(i))\n",
    "#     blurred, mask = draw_contours(image)\n",
    "#     sheet = mask\n",
    "#     show_images([image,mask, sheet ], ['image', 'mask', 'sheet'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perspective_transform_image(img, margin = 30):\n",
    "    # Read the image\n",
    "    image = np.copy(img)\n",
    "    \n",
    "    # get the source points \n",
    "    image = deskew_image(image)\n",
    "    box, mask = draw_contours(image)\n",
    "    [xmin, xmax, ymin, ymax]= box \n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = color.rgb2gray(image)\n",
    "\n",
    "    source_points = np.array( [[0, 0] ,[3000, 0 ] ,[0, 3000] ,[3000 ,3000]] )\n",
    "\n",
    "    # Define the destination points (a rectangle)\n",
    "    destination_points = np.array([[xmin+margin, ymin+margin],  [xmax-margin, ymin+margin], [xmin+margin,ymax-margin], [xmax-margin, ymax-margin]])\n",
    "\n",
    "    # Estimate the perspective transform\n",
    "    tform = transform.ProjectiveTransform()\n",
    "    tform.estimate(source_points, destination_points)\n",
    "\n",
    "    # Apply the perspective transformation to the image\n",
    "    transformed_image = transform.warp(image, tform, output_shape=(3000, 3000))\n",
    "\n",
    "    return transformed_image\n",
    "\n",
    "\n",
    "# for i in range(1,2):\n",
    "#     image = io.imread('grade_sheet/{}.jpg'.format(i))\n",
    "#     show_images([image,perspective_transform_image(image)], ['image', 'perspective_transform_image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread('grade_sheet/1.jpg')\n",
    "processed_image = perspective_transform_image(image,   )\n",
    "#show_images([image,processed_image], ['image', 'processed_image'])\n",
    "\n",
    "image = np.copy(processed_image)\n",
    "blurred = rgb2gray(image)\n",
    "blurred = blurred > .5\n",
    "blurred = morphology.closing(blurred, morphology.square(6))\n",
    "label_image = measure.label(blurred)\n",
    "# Find contours using scikit-image\n",
    "cnts = measure.find_contours(label_image, .5)\n",
    "\n",
    "max_area = 0\n",
    "max_box = None\n",
    "for cnt in cnts:\n",
    "    Xmin = int(round(min(cnt[:,1])))\n",
    "    Xmax = int(round(max(cnt[:,1])))\n",
    "    Ymin = int(round(min(cnt[:,0])))\n",
    "    Ymax = int(round(max(cnt[:,0])))\n",
    "\n",
    "    width = abs( Xmax - Xmin) \n",
    "    height = abs(Ymax - Ymin)\n",
    "    area = width * height \n",
    "    \n",
    "    \n",
    "    if area > max_area:\n",
    "        max_area = area \n",
    "        max_box = [Xmin, Xmax, Ymin, Ymax]\n",
    "\n",
    "    rr, cc = rectangle(start = (Ymin,Xmin), end = (Ymax,Xmax), shape=image.shape)\n",
    "    image[rr, cc] = 1 \n",
    "\n",
    "\n",
    "#show_images([image], ['img'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(7065037)11:13 : 11006 000 - الجيزة الر ثيسي - 45 - 20105 : وممنتقم ا (651010326) عصتاعبا 112 مساععا عم كنا وق 2021-ااوع\\n\\n112008 الكناعمع]\\n\\nتلات ...1 سمي أستسيع 2076 500201 | |\\n17 ل\\nالح ونال ار لوو وي\\nامات فاو و ل ا\\n11880655\\n\\nيه\\n0\\n\\nاع 6331 1020100606 ١ادااحروطح\\u200f\\n\\nعبد الله محمد جلال السحيمى | 1180255\\nا ا أ \\u200e١\\u200f كمسا ممه سم عم الاي عبس ع\\nا 1 الست وير\\n\\u200e١\\u200f ك2 | بدي بستقادة رهم اوماد دوه أعير مسد قي هلقي خبروى .| ينوع\\nالأ ان لالت ل 5 ربج و\\nفجت معلا 2610 0553003 122\\nا ا \\u200e١\\u200f شه حا وه دم ل اله ميب |لبصسم\\nا 0 رس مان ل تور لتب ور\\n\\u200e١ 11\\u200f خنطا ا رمه ته مسيسي اننا اانا سند قشي | دمت\\n1 شطع 2 222 1105:2123 116002 11/105132 أمصطفى نخذ فى عزت حافظ\\nلاا رثن الوك مر ا أل تقار المسميسي و\\n7 20665 لاط21] 2واح ك2166/يا\\n\\nالحا وداىيا\\nايا\\n\\nس0\\n1\\n\\n0\\n1\\n\\nاح\\n\\nتا\\n\\nلد\\n\\nلاك\\n541\\n\\n12 ع3\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pytesseract \n",
    "# change this if you are not running on windows \n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:/Program Files/Tesseract-OCR/tesseract.exe\"\n",
    "\n",
    "\n",
    "image = io.imread('grade_sheet/1.jpg')\n",
    "\n",
    "pytesseract.image_to_string(image, lang='ara', config='.')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
